{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change Log\n",
    "---\n",
    "Tested CNN and and RNNwithAttention\n",
    "aDDED MERGE LAYER\n",
    "aDDED FFN AR THE END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/sunil.patel/PycharmProjects/extensibleFramework/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from extensibleFramework.src.models import convolution_neural_network\n",
    "from extensibleFramework.src.models import recurrent_nn_with_attention\n",
    "from extensibleFramework.src.models import feed_forward_network\n",
    "from extensibleFramework.src.models import extra_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torchtext import data\n",
    "import nltk\n",
    "import json\n",
    "from torchtext import vocab\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "import random\n",
    "import tarfile\n",
    "import urllib\n",
    "from torchtext import data\n",
    "import datetime\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # DataSource : http://www.cs.cornell.edu/people/pabo/movie-review-data/\n",
    "# !wget http://www.cs.cornell.edu/people/pabo/movie-review-data/rt-polaritydata.tar.gz\n",
    "# !tar -xvf rt-polaritydata.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEED = 1\n",
    "# split = 0.80\n",
    "# data_block = []\n",
    "# negative_data  = open('rt-polaritydata/rt-polarity.neg',encoding='utf8',errors='ignore').read().splitlines()\n",
    "# for i in negative_data:\n",
    "#         data_block.append({\"sentiment\":str(i.strip()),\"label\" : 0}) \n",
    "# positve_data  = open('rt-polaritydata/rt-polarity.pos',encoding='utf8',errors='ignore').read().splitlines()\n",
    "# for i in positve_data:\n",
    "#         data_block.append({\"sentiment\":str(i.strip()),\"label\" : 1}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random.shuffle(data_block)\n",
    "\n",
    "# train_file = open('train.json', 'w')\n",
    "# test_file = open('test.json', 'w')\n",
    "# for i in  range(0,int(len(data_block)*split)):\n",
    "#     train_file.write(str(json.dumps(data_block[i]))+\"\\n\")\n",
    "# for i in  range(int(len(data_block)*split),len(data_block)):\n",
    "#     test_file.write(str(json.dumps(data_block[i]))+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sentiments):\n",
    "#     print(sentiments)\n",
    "    return sentiments\n",
    "def pad_to_equal(x):\n",
    "    if len(x) < 61:\n",
    "        return x + ['<pad>' for i in range(0, 61 - len(x))]\n",
    "    else:\n",
    "        return x[:61]\n",
    "def to_categorical(x):\n",
    "    if x == 1:\n",
    "        return [0,1]\n",
    "    if x == 0:\n",
    "        return [1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENTIMENT = data.Field(sequential=True , preprocessing =pad_to_equal , use_vocab = True, lower=True,batch_first=True)\n",
    "LABEL = data.Field(is_target=True,use_vocab = False, sequential=False, preprocessing =to_categorical)\n",
    "fields = {'sentiment': ('sentiment', SENTIMENT), 'label': ('label', LABEL)}\n",
    "train_data , test_data = data.TabularDataset.splits(\n",
    "                            path = '',\n",
    "                            train = 'train.json',\n",
    "                            test = 'test.json',\n",
    "                            format = 'json',\n",
    "                            fields = fields)\n",
    "\n",
    "SENTIMENT.build_vocab(train_data, test_data)\n",
    "LABEL.build_vocab(train_data, test_data)\n",
    "train_iter, test_iter = data.Iterator.splits(\n",
    "        (train_data, test_data), sort_key=lambda x: len(x.sentiment),\n",
    "        batch_sizes=(16,len(test_data)), device=device,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 61]) torch.Size([16, 2])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_iter:\n",
    "    feature, target = batch.sentiment, batch.label\n",
    "    print(feature.data.shape, target.data.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "class ensemble_model(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, class_num, \\\n",
    "                 out_channel_num, kernel_size, dropout, input_size, hidden_size, batch_size, n_layers=1, rnn_unit=\"GRU\"):\n",
    "        super(ensemble_model, self).__init__() \n",
    "        self.cnn = convolution_neural_network.cnn_text(vocab_size, embed_dim, class_num, out_channel_num, kernel_size, dropout)\n",
    "        self.rnn_attention = recurrent_nn_with_attention.RNNAttentionModel(output_size=class_num, hidden_size=hidden_size,\\\n",
    "                                                                          vocab_size=vocab_size, embedding_length=embed_dim, \\\n",
    "                                                                          batch_size=batch_size)\n",
    "        self.merge_layer = extra_layers.MergeAndFlattern(mode=\"CONCAT\",batch_size=batch_size)\n",
    "        self.ffn = feed_forward_network.ffn(activation = \"Relu\", num_layer = 3 , input_size = 2000 , output_size = 2, perceptron_per_layer = [1000,500,250] , dropout = [0.2,0.2,0.2])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        cnn_output = self.cnn(x)\n",
    "        rnnAttention_output = self.rnn_attention(x)\n",
    "        merge_layer_output = self.merge_layer(cnn_output,rnnAttention_output )\n",
    "        final_output = self.ffn(merge_layer_output)\n",
    "        print(\"cnn_output : \",cnn_output.shape)\n",
    "        print(\"rnn_input : \",rnnAttention_output.shape)\n",
    "        print(\"merge_layer_output : \", merge_layer_output.shape)\n",
    "        print(\"final_output : \", final_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 10\n",
    "hidden_size = 128\n",
    "batch_size = 8\n",
    "n_layers = 1\n",
    "vocab_size = 5\n",
    "embed_dim  = 100\n",
    "class_num =  1000\n",
    "out_channel_num = 8\n",
    "kernel_sizes = [2,3,4]\n",
    "dropout = 0.5\n",
    "\n",
    "EM  = ensemble_model(vocab_size=vocab_size, embed_dim=embed_dim, class_num=class_num,out_channel_num=out_channel_num,\\\n",
    "                    kernel_size=kernel_sizes, dropout=dropout, input_size = input_size, hidden_size=hidden_size,\\\n",
    "                    batch_size = batch_size, n_layers = n_layers, rnn_unit = \"GRU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_input = torch.Tensor(np.random.randint(5, size=[8, 10])).long()\n",
    "rnn_input = torch.Tensor(np.random.random([8, 10])).long() #batch_size, input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn_output :  torch.Size([8, 1000])\n",
      "rnn_input :  torch.Size([8, 1000])\n",
      "merge_layer_output :  torch.Size([8, 2000])\n",
      "final_output :  torch.Size([8, 2])\n"
     ]
    }
   ],
   "source": [
    "EM(cnn_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
