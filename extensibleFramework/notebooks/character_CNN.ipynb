{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character-level Convolutional Networks for text Classification\n",
    "https://arxiv.org/pdf/1509.01626.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torchtext import data\n",
    "import nltk\n",
    "import json\n",
    "from torchtext import vocab\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from tensorboardX import SummaryWriter\n",
    "import random\n",
    "import chakin\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "import random\n",
    "import tarfile\n",
    "import torch.nn.functional as F\n",
    "import urllib\n",
    "from torchtext import data\n",
    "import datetime\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_FILTERS = 32 # number of convolutional filters per convolutional layer\n",
    "NUM_OUTPUTS = 2 # number of classes\n",
    "FULLY_CONNECTED = 128 # number of unit in the fully connected dense layer\n",
    "DROPOUT_RATE = 0.2 # probability of node drop out\n",
    "LEARNING_RATE = 0.1 # learning rate of the gradient\n",
    "MOMENTUM = 0.9 # momentum of the gradient\n",
    "WDECAY = 0.00001 # regularization term to limit size of weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ALPHABET = list(\"abcdefghijklmnopqrstuvwxyz0123456789-,;.!?:'\\\"/\\\\|_@#$%^&*~`+ =<>()[]{}\") # The 69 characters as specified in the paper\n",
    "ALPHABET_INDEX = {letter: index for index, letter in enumerate(ALPHABET)} # { a: 0, b: 1, etc}\n",
    "FEATURE_LEN = 64 # max-length in characters for one document\n",
    "BATCH_SIZE = 8 # number of documents per batch\n",
    "FEATURE_LENGTH = len(list(ALPHABET))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SEED = 1\n",
    "# split = 0.80\n",
    "# data_block = []\n",
    "# negative_data  = open('rt-polaritydata/rt-polarity.neg',encoding='utf8',errors='ignore').read().splitlines()\n",
    "# for i in negative_data:\n",
    "#         data_block.append([str(i.strip()),0]) \n",
    "# positve_data  = open('rt-polaritydata/rt-polarity.pos',encoding='utf8',errors='ignore').read().splitlines()\n",
    "# for i in positve_data:\n",
    "#         data_block.append([str(i.strip()), 1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# review = [i[0] for i in data_block]\n",
    "# sentment = [i[1] for i in data_block]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dataset = pd.DataFrame({'review':review,'sentment':sentment})\n",
    "# dataset = dataset.sample(frac=1).reset_index(drop=True)\n",
    "# dataset = dataset.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"labeledTrainData.tsv\",sep=\"\\t\")\n",
    "# dataset = pd.DataFrame({'review':review,'sentment':sentment})\n",
    "dataset = dataset.sample(frac=1).reset_index(drop=True)\n",
    "dataset = dataset[[\"review\",\"sentiment\"]].values\n",
    "# print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class data_loader():\n",
    "    def encode(self, text):\n",
    "        encoded = np.zeros([len(ALPHABET), FEATURE_LEN], dtype='float32')\n",
    "        review = text.lower()[:FEATURE_LEN-1:-1]\n",
    "        i = 0\n",
    "        for letter in text:\n",
    "            if i >= FEATURE_LEN:\n",
    "                break;\n",
    "            if letter in ALPHABET_INDEX:\n",
    "                encoded[ALPHABET_INDEX[letter]][i] = 1\n",
    "            i += 1\n",
    "        return encoded\n",
    "    \n",
    "    def transform(self,x, y):\n",
    "        if y == 0:\n",
    "            y = [1,0]\n",
    "        else:\n",
    "            y = [0,1]\n",
    "        return self.encode(x), y\n",
    "    \n",
    "    def split(self, dataset, split_ratio):\n",
    "        random.shuffle(dataset)\n",
    "        train_data = dataset[0:int(len(dataset)*split_ratio)]\n",
    "        test_data = dataset[int(len(dataset)*split_ratio):]\n",
    "        return train_data, test_data\n",
    "    \n",
    "    def get_train_data(self,train_data):\n",
    "        \n",
    "        for i in range(int(len(train_data)/BATCH_SIZE)):\n",
    "            processed_data = []\n",
    "            onehot_labels = []\n",
    "            for review, label in train_data[i*BATCH_SIZE:(i+1)*BATCH_SIZE]:\n",
    "                x, y  = self.transform(review, label)\n",
    "                processed_data.append(x)\n",
    "                onehot_labels.append(y)\n",
    "            if len(processed_data) == BATCH_SIZE:\n",
    "                yield np.asarray(processed_data), np.asarray(onehot_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 69, 64) (8, 2)\n",
      "[[0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n"
     ]
    }
   ],
   "source": [
    "DL = data_loader()\n",
    "train_iterator, test_iterator = DL.split(dataset, 0.8)\n",
    "for x,y in DL.get_train_data(train_iterator):\n",
    "    print(x.shape, y.shape)\n",
    "    print(y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class charcterCNN(torch.nn.Module):\n",
    "    def __init__(self,NUM_FILTERS, BATCH_SIZE, FULLY_CONNECTED, DROPOUT_RATE, NUM_OUTPUTS, FEATURE_LENGTH):\n",
    "        super(charcterCNN, self).__init__()\n",
    "        self.NUM_FILTERS = NUM_FILTERS \n",
    "        self.BATCH_SIZE = BATCH_SIZE \n",
    "        self.FULLY_CONNECTED  =FULLY_CONNECTED\n",
    "        self.DROPOUT_RATE = DROPOUT_RATE\n",
    "        self.NUM_OUTPUTS = NUM_OUTPUTS\n",
    "        self.FEATURE_LENGTH = FEATURE_LENGTH\n",
    "        \n",
    "        self.conv1 = torch.nn.Conv1d(in_channels=FEATURE_LENGTH, out_channels=NUM_FILTERS, kernel_size=3, stride=2)\n",
    "        self.pool1 = torch.nn.MaxPool1d(kernel_size=3,stride=3)\n",
    "        self.conv2 = torch.nn.Conv1d(in_channels=NUM_FILTERS, out_channels=NUM_FILTERS, kernel_size=3, stride=2)\n",
    "        self.pool2 = torch.nn.MaxPool1d(kernel_size=3,stride=3)\n",
    "        self.conv3 = torch.nn.Conv1d(in_channels=NUM_FILTERS, out_channels=NUM_FILTERS, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv4 = torch.nn.Conv1d(in_channels=NUM_FILTERS, out_channels=NUM_FILTERS, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv5 = torch.nn.Conv1d(in_channels=NUM_FILTERS, out_channels=NUM_FILTERS, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv6 = torch.nn.Conv1d(in_channels=NUM_FILTERS, out_channels=NUM_FILTERS, kernel_size=3, stride=2,padding=1)\n",
    "        self.pool3 = torch.nn.MaxPool1d(kernel_size=3,stride=3)\n",
    "        self.dense1 = torch.nn.Linear(NUM_FILTERS, FULLY_CONNECTED)\n",
    "        self.dropout1 = torch.nn.Dropout(DROPOUT_RATE)\n",
    "        self.dense2 = torch.nn.Linear(FULLY_CONNECTED, FULLY_CONNECTED)\n",
    "        self.dropout2 = torch.nn.Dropout(DROPOUT_RATE)\n",
    "        self.dense3 = torch.nn.Linear(FULLY_CONNECTED, NUM_OUTPUTS)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        conv1_out = F.relu(self.conv1(x))\n",
    "        pool1_out = self.pool1(conv1_out)\n",
    "        conv2_out = F.relu(self.conv2(pool1_out))\n",
    "        pool2_out = self.pool1(conv2_out)\n",
    "        conv3_out = F.relu(self.conv3(pool2_out))\n",
    "#         conv4_out = F.relu(self.conv4(conv3_out))\n",
    "#         conv5_out = F.relu(self.conv5(conv4_out))\n",
    "#         conv6_out = F.relu(self.conv6(conv5_out))\n",
    "        pool3_out = self.pool3(conv3_out)\n",
    "#         print(pool3_out.shape)\n",
    "        flatten = pool3_out.view(self.BATCH_SIZE,-1)\n",
    "#         print(\"flatten.shape : \",flatten.shape)\n",
    "        dense1_out = F.relu(self.dense1(flatten))\n",
    "        dropout1_out = self.dropout1(dense1_out)\n",
    "        dense2_out =  F.relu(self.dense2(dropout1_out))\n",
    "        dropout2_out = self.dropout2(dense2_out)\n",
    "        dense3_out = F.relu(self.dense3(dropout2_out))\n",
    "        return torch.softmax(dense3_out, dim=1)\n",
    "character_network = charcterCNN(NUM_FILTERS, BATCH_SIZE, FULLY_CONNECTED, DROPOUT_RATE,NUM_OUTPUTS, FEATURE_LENGTH)\n",
    "character_network = character_network.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.randn([8, 69, 32])\n",
    "character_network(input.to(device)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(character_network.parameters(), lr=LEARNING_RATE, weight_decay=WDECAY)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "#     print(preds.shape, y.shape)\n",
    "    rounded_preds = torch.argmax(preds, dim=1)\n",
    "    \n",
    "    correct = (rounded_preds == torch.argmax(y, dim=1)).float() #convert into float for division \n",
    "    acc = correct.sum()/len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5000)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_accuracy(torch.Tensor([[0.1,0.9],[0.1,0.9],[0.1,0.9],[0.1,0.9]]), torch.Tensor([[0,1],[0,1],[1,0],[1,0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_accuracy_calculator(character_network, test_iterator):\n",
    "    epoch_acc = 0\n",
    "    for X, Y in DL.get_train_data(test_iterator):\n",
    "        X  =torch.Tensor(x).to(device)\n",
    "        Y = torch.Tensor(Y).to(device)\n",
    "#         print(\">>\", X.shape, Y.shape)\n",
    "        predictions = character_network(X)            \n",
    "        acc = binary_accuracy(predictions.type(torch.FloatTensor), Y.type(torch.FloatTensor))\n",
    "        epoch_acc += acc.item()\n",
    "    return  epoch_acc / len(test_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(character_network, iterator,  optimizer, criterion):\n",
    "    DL = data_loader()\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    train_data, test_data = DL.split(dataset, 0.8)\n",
    "    for X,Y in DL.get_train_data(train_data):\n",
    "#         print(x.shape, y.shape)\n",
    "        X  =torch.Tensor(x).to(device)\n",
    "        Y = torch.Tensor(Y).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        predictions = character_network(X)\n",
    "        loss = criterion(predictions.type(torch.FloatTensor), Y.type(torch.FloatTensor))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        acc = binary_accuracy(predictions.type(torch.FloatTensor), Y.type(torch.FloatTensor))\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    return character_network, epoch_loss / len(iterator), epoch_acc / len(iterator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0924488228738308\n",
      "0.09518883235156536\n",
      "0.09429516029357911\n",
      "0.08860195954144001\n",
      "0.08540533438920975\n",
      "0.08154082601070405\n",
      "0.07792498716413974\n",
      "0.08994163453876972\n",
      "0.08307997691333294\n",
      "0.06881366467475891\n",
      "0.06648885649442672\n",
      "0.06487378827631474\n",
      "0.06403036640286446\n",
      "0.0634362035870552\n",
      "0.06311130195856095\n",
      "0.06295889728963375\n",
      "0.06292067487239837\n",
      "0.0629086206138134\n",
      "0.06290532306134701\n",
      "0.06290215365588665\n",
      "0.06290182130336762\n",
      "0.06290201703906059\n",
      "0.06290200054943562\n",
      "0.06290223934054374\n",
      "0.0629019049346447\n",
      "0.06290198749005795\n",
      "0.06290249069333076\n",
      "0.06290228542089463\n",
      "0.06290199010074139\n",
      "0.06290236303508281\n",
      "0.06290201343894004\n",
      "0.06290208487510682\n",
      "0.06290249494314194\n",
      "0.06290163386464119\n",
      "0.06290221158266067\n",
      "0.06290384095013142\n",
      "0.06290182429850101\n",
      "0.06290205989778042\n",
      "0.06290219406187535\n",
      "0.06290161255896091\n",
      "0.06290266713202\n",
      "0.0629025886029005\n",
      "0.06290187209546566\n",
      "0.06290186500251294\n",
      "0.06290189984738827\n",
      "0.06290224293768405\n",
      "0.06290164383649827\n",
      "0.0629022698611021\n",
      "0.06290161883831025\n",
      "0.06290200825631619\n",
      "0.06290245959758758\n",
      "0.06290199663043022\n",
      "0.06290414645075798\n",
      "0.06290228064060212\n",
      "0.06290222231149674\n",
      "0.06290161567032337\n",
      "0.0629024394094944\n",
      "0.06290245999097824\n",
      "0.06290178083479404\n",
      "0.06290172548294068\n",
      "0.06290196052491664\n",
      "0.06290209580659867\n",
      "0.06290176154077053\n",
      "0.06290226809680462\n",
      "0.06290185497403145\n",
      "0.06290180569887162\n",
      "0.06290190553367138\n",
      "0.06290230772197247\n",
      "0.06290168403685092\n",
      "0.06290249864757061\n",
      "0.06290175703763962\n",
      "0.06290203411281109\n",
      "0.06290229272842407\n",
      "0.06290145873129367\n",
      "0.0629018704533577\n",
      "0.0629026469886303\n",
      "0.06290339762866497\n",
      "0.06290185533463954\n",
      "0.06290260336101056\n",
      "0.06290206664800643\n",
      "0.06290516657233239\n",
      "0.06290267693996429\n",
      "0.06290416076779365\n",
      "0.06290159358382225\n",
      "0.06290162639319896\n",
      "0.06290353991389275\n",
      "0.06290256066322326\n",
      "0.06290168111920356\n",
      "0.06290388025045394\n",
      "0.06290185889899731\n",
      "0.06290256488323212\n",
      "0.06290419735908508\n",
      "0.0629019696176052\n",
      "0.06290204808712005\n",
      "0.06290205529928207\n",
      "0.06290190055072307\n",
      "0.06290227560698985\n",
      "0.06290174805521966\n",
      "0.06290170151591301\n",
      "0.06290197992622852\n",
      "0.06290229944884777\n",
      "0.0629018641769886\n",
      "0.06290224814713001\n",
      "0.06290167474746704\n",
      "0.06290207301974296\n",
      "0.06290201158523559\n",
      "0.06290444664061069\n",
      "0.06290249907076359\n",
      "0.06290190737247467\n",
      "0.06290232248306274\n",
      "0.0629019092977047\n",
      "0.06290217029750347\n",
      "0.06290190852284432\n",
      "0.06290272192656994\n",
      "0.06290209688544274\n",
      "0.06290180147886276\n",
      "0.06290209552049637\n",
      "0.06290200602412224\n",
      "0.06290223173499107\n",
      "0.06290234555006027\n",
      "0.06290220558345318\n",
      "0.06290168728530407\n",
      "0.06290252466499806\n",
      "0.06290181969404221\n",
      "0.06290225698947907\n",
      "0.06290213506519794\n"
     ]
    }
   ],
   "source": [
    "epochs  = 500\n",
    "log_interval = 1\n",
    "loss = []\n",
    "accuracy = []\n",
    "test_accuracy = []\n",
    "writer = SummaryWriter()\n",
    "for i in range(epochs):\n",
    "    character_network, epoch_loss, epoch_acc = train(character_network, train_iterator, optimizer, criterion)\n",
    "    test_acc = test_accuracy_calculator(character_network, test_iterator)\n",
    "    accuracy.append(epoch_acc)\n",
    "    loss.append(epoch_loss)\n",
    "    test_accuracy.append(test_acc)\n",
    "    writer.add_scalar('Traing Loss',epoch_loss, i)\n",
    "    writer.add_scalar('Test Accuracy',test_acc, i)\n",
    "    writer.add_scalar('Train Accuracy',epoch_acc, i)\n",
    "    print(epoch_loss)\n",
    "writer.export_scalars_to_json(\"./all_scalars.json\")\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
