{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change Log\n",
    "---\n",
    "Restructuring code, hadelling parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/data/extensibleFramework/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from extensibleFramework.src.models import convolution_neural_network\n",
    "from extensibleFramework.src.models import recurrent_nn_with_attention\n",
    "from extensibleFramework.src.models import feed_forward_network\n",
    "from extensibleFramework.src.models import extra_layers\n",
    "from extensibleFramework.src.utils import saving_and_loading\n",
    "from extensibleFramework.src.models import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import chakin\n",
    "import matplotlib.pyplot as plt\n",
    "from torchtext import data\n",
    "import nltk\n",
    "import json\n",
    "from torchtext import vocab\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import random\n",
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "import random\n",
    "import tarfile\n",
    "import urllib\n",
    "from torchtext import data\n",
    "import datetime\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_frame = pd.read_csv(\"labeledTrainData.tsv\",sep=\"\\t\")\n",
    "data_frame = data_frame[['review', 'sentiment']]\n",
    "data_block  = data_frame.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SEED = 1\n",
    "split = 0.80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.shuffle(data_block)\n",
    "\n",
    "# train_file = open('train.json', 'w')\n",
    "# test_file = open('test.json', 'w')\n",
    "# for i in  range(0,int(len(data_block)*split)):\n",
    "#     train_file.write(str(json.dumps({'review' : data_block[i][0], 'label' : data_block[i][1]}))+\"\\n\")\n",
    "# for i in  range(int(len(data_block)*split),len(data_block)):\n",
    "#     test_file.write(str(json.dumps({'review' : data_block[i][0], 'label' : data_block[i][1]}))+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize(sentiments):\n",
    "    \n",
    "    return nltk.tokenize.word_tokenize(sentiments)\n",
    "# def pad_to_equal(x):\n",
    "#     if len(x) < 61:\n",
    "#         return x + ['<pad>' for i in range(0, 61 - len(x))]\n",
    "#     else:\n",
    "#         return x[:61]\n",
    "def to_categorical(x):\n",
    "    x = int(x)\n",
    "    if x == 1:\n",
    "        return [0,1]\n",
    "    if x == 0:\n",
    "        return [1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENTIMENT = data.Field(sequential=True , tokenize=tokenize, use_vocab = True, lower=True,batch_first=True)\n",
    "LABEL = data.Field(is_target=True,use_vocab = False, sequential=False, preprocessing = to_categorical)\n",
    "fields = {'sentiment': ('sentiment', SENTIMENT), 'label': ('label', LABEL)}\n",
    "train_data , test_data = data.TabularDataset.splits(\n",
    "                            path = '',\n",
    "                            train = 'train.json',\n",
    "                            test = 'test.json',\n",
    "                            format = 'json',\n",
    "                            fields = fields)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# chakin.search(lang='English')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# chakin.download(number=12, save_dir = \"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !unzip glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vec = vocab.Vectors(name = \"glove.6B.100d.txt\",cache = \"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SENTIMENT.build_vocab(train_data, test_data, max_size=400000, vectors=vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentiment_vocab = SENTIMENT.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining config object \n",
    "cnn_rnn_vocab_size = len(SENTIMENT.vocab)\n",
    "cnn_rnn_embed_dim = 100\n",
    "cnn_rnn_class_num = 50\n",
    "out_channel_num = 8\n",
    "cnn_kernel_sizes = [3,4,5]\n",
    "rnn_n_layers = 1\n",
    "rnn_hidden_size = 128\n",
    "use_pretrained_weights = True\n",
    "cnn_rnn_weights = sentiment_vocab.vectors\n",
    "cnn_rnn_weight_is_trainable =  False\n",
    "dropout = 0.2\n",
    "batch_size = 32\n",
    "merge_mode = \"CONCAT\"\n",
    "ffn_activation = \"Relu\"\n",
    "ffn_final_output_classes = 2\n",
    "ffn_num_layer = 2 \n",
    "ffn_perceptron_per_layer = [50, 25]\n",
    "ffn_layer_wise_dropout = [0.2,0.2]\n",
    "device = device\n",
    "\n",
    "config = config.Config(cnn_rnn_vocab_size, cnn_rnn_embed_dim, cnn_rnn_class_num, out_channel_num, \\\n",
    "        cnn_kernel_sizes, rnn_n_layers, rnn_hidden_size, use_pretrained_weights,cnn_rnn_weights, cnn_rnn_weight_is_trainable,\\\n",
    "            dropout, batch_size, merge_mode, ffn_activation, ffn_final_output_classes, ffn_num_layer, ffn_perceptron_per_layer,\\\n",
    "                       ffn_layer_wise_dropout, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iter, test_iter = data.Iterator.splits(\n",
    "        (train_data, test_data), sort_key=lambda x: len(x.sentiment),\n",
    "        batch_sizes=(batch_size,batch_size), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 46]) torch.Size([32, 2])\n"
     ]
    }
   ],
   "source": [
    "for batch in test_iter:\n",
    "    feature, target = batch.sentiment, batch.label\n",
    "    print(feature.data.shape, target.data.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([118522, 100])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_vocab.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "class ensemble_model(nn.Module):\n",
    "    def __init__(self, config_object):\n",
    "        super(ensemble_model, self).__init__() \n",
    "        self.cnn = convolution_neural_network.cnn_text(config_object)\n",
    "        self.rnn_attention = recurrent_nn_with_attention.RNNAttentionModel(config_object)\n",
    "        self.merge_layer = extra_layers.MergeAndFlattern(config_object)\n",
    "        self.ffn = feed_forward_network.ffn(config_object)\n",
    "    def forward(self, x):\n",
    "        cnn_output = self.cnn(x)\n",
    "        rnnAttention_output = self.rnn_attention(x)\n",
    "        merge_layer_output = self.merge_layer(cnn_output,rnnAttention_output )\n",
    "        final_output = self.ffn(merge_layer_output)\n",
    "        \n",
    "#         print(\"cnn_output : \",cnn_output.shape)\n",
    "#         print(\"rnn_input : \",rnnAttention_output.shape)\n",
    "#         print(\"merge_layer_output : \", merge_layer_output.shape)\n",
    "#         print(\"final_output : \", final_output.shape)\n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "EM  = ensemble_model(config)\n",
    "EM  = EM.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn_input = torch.Tensor(np.random.randint(5, size=[8, 10])).long().to(device)\n",
    "rnn_input = torch.Tensor(np.random.random([8, 10])).long().to(device) #batch_size, input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# EM(rnn_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "    rounded_preds = torch.argmax(preds, dim=1)\n",
    "    correct = (rounded_preds == torch.argmax(y, dim=1)).float() #convert into float for division \n",
    "    acc = correct.sum()/len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        feature, target = batch.sentiment, batch.label\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(feature.to(device))            \n",
    "        loss = criterion(predictions.type(torch.FloatTensor), target.type(torch.FloatTensor))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        acc = binary_accuracy(predictions.type(torch.FloatTensor), target.type(torch.FloatTensor))\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    return model, epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_accuracy_calculator(model, test_iterator):\n",
    "    epoch_acc = 0\n",
    "    for batch in test_iterator:\n",
    "        if batch.sentiment.shape[0] ==  32:\n",
    "            feature, target = batch.sentiment, batch.label\n",
    "            predictions = model(feature.to(device))            \n",
    "            acc = binary_accuracy(predictions.type(torch.FloatTensor), target.type(torch.FloatTensor))\n",
    "            epoch_acc += acc.item()\n",
    "    return  epoch_acc / len(test_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(EM.parameters(), lr=0.1,momentum=0.9)\n",
    "criterion = nn.MSELoss()\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:45<1:15:52, 45.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.50305 0.4964171974522293 0.25141215829849245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 2/100 [01:31<1:15:05, 45.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49855 0.4964171974522293 0.25117810282707215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 3/100 [02:17<1:14:12, 45.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5016 0.5027866242038217 0.2511367109537125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 4/100 [03:03<1:13:25, 45.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5182 0.5177149681528662 0.2497864093542099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 5/100 [03:49<1:12:39, 45.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5399 0.5388136942675159 0.24802309081554413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 6/100 [04:34<1:11:37, 45.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5597 0.5320461783439491 0.24426858680248262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 7/100 [05:20<1:10:56, 45.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5915 0.6683917197452229 0.23709056327342987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 8/100 [06:06<1:10:09, 45.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75305 0.7931926751592356 0.1692109164893627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▉         | 9/100 [06:51<1:09:18, 45.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8228 0.7906050955414012 0.12881819457411767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 10/100 [07:37<1:08:26, 45.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8436 0.8302149681528662 0.11626528443098068\n",
      " === New Learning rate :  0.05  === \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 11/100 [08:22<1:07:34, 45.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8635 0.8351910828025477 0.10071855126470328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 12/100 [09:07<1:06:33, 45.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.86935 0.8326035031847133 0.09755334788858891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 13/100 [09:53<1:05:48, 45.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.87125 0.8385748407643312 0.09576871104240417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 14/100 [10:38<1:05:10, 45.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.87545 0.8443471337579618 0.09379671750068665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 15/100 [11:24<1:04:29, 45.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8774 0.8278264331210191 0.09154134646505117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 16/100 [12:09<1:03:42, 45.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.87755 0.8501194267515924 0.09243871095478534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 17/100 [12:55<1:02:59, 45.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.88225 0.835390127388535 0.08998507573902607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 18/100 [13:40<1:02:10, 45.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.88105 0.8389729299363057 0.08859414272382855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▉        | 19/100 [14:26<1:01:28, 45.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.88355 0.8405652866242038 0.08683306982517243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 20/100 [15:12<1:00:45, 45.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.88545 0.8332006369426752 0.08661036605983972\n",
      " === New Learning rate :  0.025  === \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 21/100 [15:57<59:52, 45.48s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.89435 0.8517117834394905 0.0804198376044631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 22/100 [16:42<59:06, 45.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8965 0.8503184713375797 0.07852811520248651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 23/100 [17:28<58:27, 45.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.89675 0.8544984076433121 0.07840549196749926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 24/100 [18:14<57:46, 45.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.89895 0.8542993630573248 0.07745279272124171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 25/100 [18:59<56:52, 45.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.90035 0.8519108280254777 0.07724480876177549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 26/100 [19:45<56:10, 45.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.903 0.8542993630573248 0.07614348472356797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 27/100 [20:30<55:22, 45.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.90175 0.8556926751592356 0.07603939979188144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 28/100 [21:16<54:43, 45.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.90265 0.852906050955414 0.07569970350600778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 29/100 [22:02<54:05, 45.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.90695 0.8539012738853503 0.07299315198510885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 30/100 [22:47<53:10, 45.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.90565 0.8578821656050956 0.0731066860832274\n",
      " === New Learning rate :  0.0125  === \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███       | 31/100 [23:33<52:23, 45.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.91405 0.8531050955414012 0.06876057477518917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 32/100 [24:18<51:40, 45.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9132 0.8554936305732485 0.06930147396847605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 33/100 [25:04<50:49, 45.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.91455 0.8552945859872612 0.0682074833586812\n"
     ]
    }
   ],
   "source": [
    "epochs  = 100\n",
    "log_interval = 1\n",
    "loss = []\n",
    "accuracy = []\n",
    "test_accuracy = []\n",
    "for i in tqdm(range(epochs)):\n",
    "    if (i != 0 and i%10 == 0 ):\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = param_group['lr']/2\n",
    "        print (\" === New Learning rate : \", param_group['lr'], \" === \")\n",
    "    \n",
    "    model, epoch_loss, epoch_acc = train(EM, train_iter, optimizer, criterion)\n",
    "    \n",
    "    test_acc = test_accuracy_calculator(model, test_iter)\n",
    "    accuracy.append(epoch_acc)\n",
    "    loss.append(epoch_loss)\n",
    "    test_accuracy.append(test_acc)\n",
    "    print(epoch_acc,test_acc,epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SAL = saving_and_loading.objectManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAL.saver(EM, \"./EM.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EM = SAL.loader(\"./EM.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
